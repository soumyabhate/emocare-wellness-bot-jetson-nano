
# ğŸ§  EmoCare: AI Wellness Companion ğŸ§˜ğŸ»â€â™€ï¸

> *An AI-powered, empathetic wellness companion designed to provide gentle emotional support, self-reflection tools, and real-time emotion awareness.*

---

## ğŸ“Œ Project Status
**Framework:** Complete âœ…  
**Course:** Data 690 â€“ Special Topics in AI  
**Focus Areas:** Conversational AI Â· Mental Wellness Â· Edge AI  
**Deployment:** Streamlit (Web) + Jetson Nano (Edge-ready)
**Instructor:** Prof. Levan Sulimanov

---

## âœ¨ Overview

**EmoCare** is more than a chatbot â€” it is a **human-centered AI wellness companion** that helps users reflect on emotions, manage stress, and engage in mindful self-check-ins in a **non-judgmental and supportive environment**.

The system combines:
- Conversational AI
- Voice interaction
- Visual emotion sensing
- Gentle behavioral nudges

This project was developed as part of **Data 690: Special Topics in AI**, under the guidance of **Prof. Levan Sulimanov**, with a strong emphasis on **ethical, responsible AI** for mental wellness.

---

## ğŸš€ Core Features

### ğŸ’¬ Conversational Wellness AI
- Powered by **Groq LLM (Llama 3.x)**
- Emotion-aware, empathetic responses
- Contextual grounding using mood, focus area, and optional journal input

### ğŸ™ï¸ Voice Mode (STT & ğŸ”Š TTS)
- Speech-to-Text and Text-to-Speech using **ElevenLabs**
- Optional, user-controlled voice interaction

### ğŸ“– Journal-Aware Reflection
- Upload personal PDFs (journals/notes)
- Automatic anonymization
- Optional word cloud visualization

### ğŸ® Calm Quest Mini-Game
- 60-second guided grounding experience
- Breathing, grounding, and journaling

### ğŸ§ Mood-Based Music Recommendations
- YouTube playlist suggestions based on mood

### ğŸ§­ Action Compass
- Gentle, emotion-based nudges (not prescriptive)

---

## ğŸ” Update: Real-Time Facial Emotion Detection (NEW)

### ğŸ“· What Was Added
- Live facial emotion detection using webcam
- Optimized for **NVIDIA Jetson Nano**
- Fully local, privacy-preserving inference

### ğŸ§  Technical Pipeline
**Face Detection:** OpenCV YuNet (ONNX)  
**Emotion Model:** FER+ (ONNX)

Recognized emotions:
`neutral, happiness, surprise, sadness, anger, disgust, fear, contempt`

### âš¡ Performance Optimizations
- Emotion inference every 5 frames
- Resolution capped at 640Ã—480
- MJPEG + V4L2 backend
- 10-second controlled camera sessions

### ğŸ”’ Privacy
- No video storage
- No external transmission
- Explicit user control

### ğŸ“¦ Required Models
```
models/
â”œâ”€â”€ face_detection_yunet_2023mar.onnx
â””â”€â”€ emotion-ferplus-8.onnx
```

---

## ğŸ› ï¸ Installation & Setup

```bash
git clone <your-repo-link>
cd emocare
pip install -r requirements.txt
streamlit run wellness.py
```

Create a `.env` file:
```env
GROQ_API_KEY=...
ELEVENLABS_API_KEY=...
```

---

## ğŸ”® Future Work
- Multi-face tracking
- Emotion smoothing
- Text + Voice + Face fusion
- Offline Jetson-only mode

---

## ğŸ™ Acknowledgements
- Prof. Levan Sulimanov
- Groq
- ElevenLabs
- Streamlit

---

ğŸŒ± *Built with empathy, responsibility, and human-centered AI in mind.*
